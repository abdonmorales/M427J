<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" type="text/css" href="LinAlg.css">
<title>LA2 for DE</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script> 
</head>
<body>

<br>
<h1>Solving Linear Systems</h1>
<br>

<div class="sectionhead">1. Linear Systems</div>

<p class="tabbed">In this lesson, we will learn how to find the
solution set to a system of linear equations.</p>

<div class="bluebox">
A <b>Linear System</b> of $m$ linear
equations in $n$ variables is a set of equations:
$$
\begin{array}{ccc}
a_{1,1} x_1 + a_{1,2} x_2 + \cdots + a_{1,n} x_{n} & = & b_1\\
a_{2,1} x_1 + a_{2,2} x_2 + \cdots + a_{2,n} x_{n} & = & b_2\\
 \vdots & \vdots & \vdots \\
a_{m,1} x_1 + a_{m,2} x_2 + \cdots + a_{m,n} x_{n}
& = & b_{m}
\end{array}$$
where all coefficients $a_{i , \, j}$ and all constant terms $b_i$
are real numbers.
<p class="tabbed">A <b>Solution</b> of the system is a vector 
${\bf x} \in \mathbb{R}^n$ that is simultaneously a solution to 
every equation. The set of all solutions is called the <b>Solution
Set</b> of the linear system. It is a subset of $\mathbb{R}^n.$
</div>

<p class="tabbed">The case $m = n = 2$ is a pair of
simultaneous linear equations
$$a_{1,1} x + a_{1,2} y \ = \ b_1\,, \qquad
\qquad a_{2,1} x + a_{2,2} y \ = \ b_2\,, $$
in $2$ variables which can be thought of graphically as a pair of
straight lines in the plane. The solution set then consists of the 
point(s) of intersection, if any, of the lines. The various
possibilities are shown below.</p>

<table style="margin-left: auto; width: 960px;margin-right: auto;
  text-align: left;"border="0"bordercolor="lightgray" cellspacing="2" cellpadding="5">
<tbody>
<tr>
<td style="width: 320px; height: 200px; text-align: center;
  vertical-align: top;">
<p style="text-align: center;"><img
  src="LinearSys01a.png"
  alt=" " width="270" /></p>
</td>
<td style="width: 475px; height: 200px; text-align: left;
  vertical-align: top; padding-left: 0.5cm;">
<p style="text-align: center;"><img src="LinearSys01b.png" alt=" " width="270" /></p>
</td>
<td style="width: 475px; height: 200px; text-align: left;
  vertical-align: top; padding-left: 0.5cm;">
<p style="text-align: center;"><img src="LinearSys01c.png" alt=" " width="296" /></p>
</td>
</tr>
</tbody>
</table>

The first system has a unique solution because the lines
intersect in a single point. In the second and third examples, however, the lines are
  parallel, so the solution set will be empty when the parallel lines
  are distinct as in the second example, while the system will have
  infinitely many solutions when the parallel lines coincide as in the
  third case. This holds in general, as stated in the theorem below.</p>

<div class="bluebox">
<b>Theorem:</b> A general linear system will be exactly one of the 
following:
<ul class="blueul">
<li>the system is <b>Inconsistent</b>, i.e., there are no solutions 
to the system, or</li>
<li>the system is <b>Consistent</b> and has a <b>Unique Solution</b>,
or
</li>
<li>the system is <b>Consistent</b> and has <b>Infinitely Many
Solutions</b>.
</li>
</ul>
</div>

<p>To each linear system we associate two matrices:</p>

<table class="twocol">
<tbody><tr>
<td>
<b>The Coefficient Matrix:</b>
<p>The coefficients are written as rows with entries aligned so that
a column consists of the coefficients of an individual variable.</p>
$$\left[\begin{array}{cccc}
a_{1,1} & a_{1,2} & \cdots & a_{1,\, n} \\
a_{2,1} & a_{2,2} & \cdots & a_{2,\, n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m,\, 1} & a_{m,\, 2} & \cdots & a_{m,\, n} \\ 
\end{array}\right]$$
</td>
<td>
<b>The Augmented Matrix:</b> 
<p style="height: 80px;">Now <em>augment</em> the coefficient matrix by 
adding the column 
of constant terms to the right of the coefficient matrix.</p>
$$\left[\begin{array}{cccc|c}
a_{1,1} & a_{1,2} & \cdots & a_{1,\, n} & b_1 \\
a_{2,1} & a_{2,2} & \cdots & a_{2,\, n} & b_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
a_{m,\,1} & a_{m,\, 2} & \cdots & a_{m,\, n} & b_{m} \\
\end{array}\right]$$
</td>
</tr></tbody>
</table>

<p>If we let $A \in M_{m \times n}(\mathbb{R})$ be the coefficient 
matrix, and ${\bf b} \in \mathbb{R}^m$ be the vector of constants,
then the augmented matrix is 
$\left[ \begin{array}{c|c} A & {\bf b} \\ \end{array} \right]
\in M_{m \times (n+1)}(\mathbb{R}).$ The solution set
to the linear system is equal to the set
$$
\left\{ {\bf x} \in \mathbb{R}^n \, \middle\vert \,
A {\bf x} = {\bf b} \right\}.
$$</p>

<div class="greenbox">
To solve the linear system, we follow these steps:
<ul class="greenul">
<li>Create the augmented matrix associated with the linear system,
$\left[ \begin{array}{c|c} A & {\bf b} \\ \end{array} \right].$
</li>
<li>Simplify the augmented matrix using <b>Elementary Row
Operations</b>. This is called <b>Gaussian Elimination</b>.
</li>
<li>Find the unique, most simplified form of 
$\left[ \begin{array}{c|c} A & {\bf b} \\ \end{array} \right].$ This
is called the <b>Reduced Row Echelon Form (RREF)</b> of the matrix,
denoted 
RREF$\left(\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]\right).$
</li>
<li>Convert
RREF$\left(\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]\right)$
back into a linear system. Use these equations to solve the system,
and put the solution in <b>Parametric Form</b>.
</li>
</ul>
</div>

<br>

<div class="sectionhead">2. Gaussian Elimination</div>

<p class="tabbed">The following row operations are <em>exactly</em>
the operations that can be performed on an augmented matrix without
changing the solution set of the associated linear system.
</p>

<div class="bluebox">
These are the <b>Elementary Row Operations</b>:
<ul class="blueul">
<li>Interchange: Interchange two rows, denoted $R_i \leftrightarrow
R_j.$
</li>
<li>Scale: Multiply all entries in a row by a nonzero scalar $c,$
denoted $R_i \rightarrow c R_i.$
</li>
<li>Replace: Replace one row with the sum of itself and a scalar
multiple of another row, denoted $R_i \rightarrow R_i + c R_j.$
</li>
</ul>
Simplifying a matrix using the elementary row operations is 
called <b>Gaussian Elimination</b>.
</div>

<p>Let's use Gaussian Elimination to solve the following system.</p>

<table class="twocol">
<tbody><tr>
<td>
<b>Problem:</b> Solve the system
$$\begin{array}{rcc}
y + z & = &  4 \, , \\
3x + 6y -3z & = & 3 \, , \\
-2x -3y + 7z & = & 10 \, . \\ \end{array} $$

<b>Solution:</b> The associated augmented matrix is
$$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right] \ = \ 
\left[\begin{array}{ccc|c} 0 & 1 & 1 & 4 \\
3 & 6 & -3 & 3 \\ -2 & -3 & 7 & 10 \\
\end{array} \right]$$
Interchange Row 1 and Row 2:
$$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right] \ \xrightarrow{ R_1 \, \leftrightarrow \, R_2 } \
\left[\begin{array}{ccc|c} 3 & 6 & -3 & 3 \\
0 & 1 & 1 & 4 \\ -2 & -3 & 7 & 10 \\
\end{array} \right]$$
Scale the new Row 1 by $1/3$:
$$\xrightarrow{ R_1 \, \rightarrow \, \frac{1}{3}R_1 } \ 
\left[\begin{array}{ccc|c} 1 & 2 & -1 & 1 \\
0 & 1 & 1 & 4 \\ -2 & -3 & 7 & 10 \\
\end{array} \right]$$
Replace Row 3 with Row 3 plus $2$ times Row 1:
$$\xrightarrow{ R_3 \rightarrow R_3 + 2 R_1 } \ 
\left[\begin{array}{ccc|c} 1 & 2 & -1 & 1 \\
0 & 1 & 1 & 4 \\ 0 & 1 & 5 & 12 \\
\end{array} \right]$$
Replace Row 3 with Row 3 minus Row 2:
$$\xrightarrow{ R_3 \rightarrow R_3 - R_2 } \ 
\left[\begin{array}{ccc|c} 1 & 2 & -1 & 1 \\
0 & 1 & 1 & 4 \\ 0 & 0 & 4 & 8 \\
\end{array} \right]$$
</td>
<td>
Replace Row 1 with Row 1 minus $2$ times Row 2:
$$\xrightarrow{ R_1 \rightarrow R_1 - 2 R_2 } \ 
\left[\begin{array}{ccc|c} 1 & 0 & -3 & -7 \\
0 & 1 & 1 & 4 \\ 0 & 0 & 4 & 8 \\
\end{array} \right]$$
Scale Row 3 by $1/4$:
$$\xrightarrow{ R_3 \, \rightarrow \, \frac{1}{4}R_3 } \ 
\left[\begin{array}{ccc|c} 1 & 0 & -3 & -7 \\
0 & 1 & 1 & 4 \\ 0 & 0 & 1 & 2 \\
\end{array} \right]$$
Replace Row 1 with Row 1 plus $3$ times Row 3:
$$\xrightarrow{ R_1 \rightarrow R_1 + 3 R_3 } \ 
\left[\begin{array}{ccc|c} 1 & 0 & 0 & -1 \\
0 & 1 & 1 & 4 \\ 0 & 0 & 1 & 2 \\
\end{array} \right]$$
Replace Row 2 with Row 2 minus Row 3:
$$\xrightarrow{ R_2 \rightarrow R_2 - R_3 } \ 
\left[\begin{array}{ccc|c} 1 & 0 & 0 & -1 \\
0 & 1 & 0 & 2 \\ 0 & 0 & 1 & 2 \\
\end{array} \right]$$
Convert the new augmented matrix back into a linear system:
$$\begin{array}{rcc}
x & = &  -1 \, , \\
y & = & 2 \, , \\
z & = & 2 \, . \\ \end{array}$$
and we see the system is consistent with unique solution
$$
{\bf x} = \left[ \begin{array}{c} -1 \\ 2 \\ 2 \\ 
\end{array} \right].$$
</td>
</tr></tbody>
</table>

<br>

<div class="sectionhead">3. Reduced Row Echelon Form</div>

<p class="tabbed">Using Gaussian Elimination, every matrix can be
put into its unique, most simplified form, called its Reduced Row
Echelon Form (RREF).</p>

<div class="bluebox">
A matrix is in <b>Reduced Row Echelon Form</b> if
<ul class="blueul">
<li>Rows of zeroes are at the bottom of the matrix,
</li>
<li>The leftmost nonzero entry of a row is $1,$ (this entry is
called a <b>leading $1$</b>),
</li>
<li>Each leading $1$ is the only nonzero entry in its column,
</li>
<li>Leading $1$'s start in the top left and go down and to the right.
</li>
</ul>
<p>Leading $1$'s are also called <b>pivots</b>, and columns 
containing pivots are called <b>pivot columns</b>.</p>
<p>Using Gaussian Elimination, a matrix $A$ can be converted into
exactly one matrix in reduced row echelon form, called the reduced 
row echelon form of $A,$ and denoted RREF$(A).$</p>
<p>The number of pivots in RREF$(A)$ is called the <b>rank</b>
of $A.$</p>
</div>

<p>Typical structures for a matrix in Reduced Row Echelon Form are
thus</p>

$$\left[\begin{array}{ccccccccc} 
1 & \ast & 0 & 0 & \ast & 0 & \ast &  \cdots  & \ast  \\
0 & 0 & 1 & 0 & \ast & 0 & \ast & \cdots & \ast   \\
0 & 0 & 0 & 1 & \ast & 0 & \ast & \cdots  & \ast  \\
0 & 0 & 0 & 0 & 0 & 1 &  \ast  & \cdots &  \ast\\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0  \\
0 & 0 & 0 & 0 & 0 & 0 & 0 &  \cdots & 0 \end{array}\right], \quad
\qquad \left[\begin{array}{cccccccccc} 
0 & 1 & \ast & 0 & 0 & \ast & 0 & \ast &  \cdots  & \ast  \\
0 & 0 & 0 & 1 & 0 & \ast & 0 & \ast & \cdots & \ast   \\
0 & 0 & 0 & 0 & 1 & \ast & 0 & \ast & \cdots  & \ast  \\
0 & 0 & 0 & 0 & 0 & 0 & 1 &  \ast  & \cdots &  \ast\\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0  \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &  \cdots & 0 \end{array}\right]$$

where the $*$ entry can be any real number. For example, here are
all RREF matrices in $M_{2 \times 3}(\mathbb{R}):$

<table class="rrefeg1">
<tbody>
<tr>
<td>
Rank 2
</td>
<td>
$$\left[ \begin{array}{ccc} 1 & 0 & \ast  \\ 0 & 1 & \ast \\
\end{array} \right]$$
Pivot Columns 1 and 2
</td>
<td>
$$\left[ \begin{array}{ccc} 1 & \ast & 0  \\ 0 & 0 & 1 \\
\end{array} \right]$$
Pivot Columns 1 and 3
</td>
<td>
$$\left[ \begin{array}{ccc} 0 & 1 & 0  \\ 0 & 0 & 1 \\
\end{array} \right]$$
Pivot Columns 2 and 3
</td>
</tr>
<tr>
<td>
Rank 1
</td>
<td>
$$\left[ \begin{array}{ccc} 1 & \ast & \ast  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 1
</td>
<td>
$$\left[ \begin{array}{ccc} 0 & 1 & \ast  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 2
</td>
<td>
$$\left[ \begin{array}{ccc} 0 & 0 & 1  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 3
</td>
</tr>
<tr>
<td>
Rank 0
</td>
<td>
$$\left[ \begin{array}{ccc} 0 & 0 & 0  \\ 0 & 0 & 0 \\
\end{array} \right]$$
No Pivot Columns
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody></table>

<p class="tabbed">A linear system with two equations and two
variables will create a $2 \times 3$ augmented matrix,
$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right].$ The RREF of such a matrix will look like
one of the above $7$ matrices, written as an augmented matrix. See
below.
</p>

<table class="rrefeg1">
<tbody>
<tr>
<td style="border: 2px solid lightgreen; background: #e9fce9;">
$$\left[ \begin{array}{cc|c} 1 & 0 & \ast  \\ 0 & 1 & \ast \\
\end{array} \right]$$
Pivot Columns 1 and 2
</td>
<td style="border: 2px solid red; background: #ffe6e6;">
$$\left[ \begin{array}{cc|c} 1 & \ast & 0  \\ 0 & 0 & 1 \\
\end{array} \right]$$
Pivot Columns 1 and 3
</td>
<td style="border: 2px solid red; background: #ffe6e6;">
$$\left[ \begin{array}{cc|c} 0 & 1 & 0  \\ 0 & 0 & 1 \\
\end{array} \right]$$
Pivot Columns 2 and 3
</td>
</tr>
<tr>
<td style="border: 2px solid blue; background: #e6e6ff;">
$$\left[ \begin{array}{cc|c} 1 & \ast & \ast  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 1
</td>
<td style="border: 2px solid blue; background: #e6e6ff;">
$$\left[ \begin{array}{cc|c} 0 & 1 & \ast  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 2
</td>
<td style="border: 2px solid red; background: #ffe6e6;">
$$\left[ \begin{array}{cc|c} 0 & 0 & 1  \\ 0 & 0 & 0 \\
\end{array} \right]$$
Pivot Column 3
</td>
</tr>
<tr>
<td style="border: 2px solid blue; background: #e6e6ff;">
$$\left[ \begin{array}{cc|c} 0 & 0 & 0  \\ 0 & 0 & 0 \\
\end{array} \right]$$
No Pivot Columns
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody></table>

<br>

<table class="rrefeg2">
<tbody>
<tr><td style="border: 2px solid lightgreen; background: #e9fce9;">
The matrix in the top left is consistent with a unique solution. The 
equations are of the form $x = \alpha , y = \beta.$ The unique 
solution is the augmented column.
</td></tr>
<tr><td style="border: 2px solid red; background: #ffe6e6;">
The three matrices in the top right corner that have their
augmented column as a pivot column will have no solution: each of
those three matrices has a row of the form 
$\left[ \begin{array}{cc|c} 0 & 0 & 1 \\ \end{array} \right],$
which gives the linear equation $0 x + 0 y = 1,$ or $0 = 1.$ This
is impossible, so there is no solution to the system in that case.
These systems are inconsistent.
</td></tr>
<tr><td style="border: 2px solid blue; background: #e6e6ff;">
The three matrices in the lower left which are missing one or more
pivot columns to the left of the augmented column are consistent,
but they will have infinitely many solutions. This will be discussed
in detail below.
</td></tr>
</tbody></table>

<p class="tabbed">The following theorem gives the relationship
between the reduced row echelon form of an augmented matrix and the
solution set to the associated linear system.</p>

<div class="bluebox"><b>Theorem:</b> Let 
$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]$ be the augmented matrix associated with a
linear system, and let $B$ be its reduced row echelon form, 
$$B = \textrm{RREF} \left(\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]\right).$$
Then
<ul class="blueul">
<li>If the augmented column of $B$ is a pivot column, then the linear
system is <b>Inconsistent</b>.
</li>
<li>If the augmented column of $B$ is <em>NOT</em> a pivot column,
but every column to the left of the vertical bar <em>IS</em> a pivot
column, then the linear system is <b>Consistent</b> and has a 
<b>Unique Solution</b>.
</li>
<li>If the augmented column of $B$ is <em>NOT</em> a pivot column,
and some column to the left of the vertical bar is also <em>NOT</em> 
a pivot column, then the linear system is <b>Consistent</b> and 
has <b>Infinitely Many Solutions</b>.
</li>
</ul>
</div>

<br>

<div class="sectionhead" style="top: 0px;">4. Parametric Form</div>

<p class="tabbed">It is easy enough to write the solution set
for systems with a unique solution or no solution. We need a 
method for expressing the solution set to a consistent system
with infinitely many solutions.</p>

<div class="bluebox">
Let 
$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]$ be the augmented matrix associated with a
<em>consistent</em>
linear system, and let $B$ be its reduced row echelon form, 
$$B = \textrm{RREF} \left(\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right]\right).$$
The columns to the left of the vertical bar are associated with
variables in the linear system. 
<ul class="blueul">
<li>The variables associated with pivot columns are the 
<b>dependent variables</b>. 
</li>
<li>The variables associated with non-pivot columns are the
<b>independent variables</b> or <b>free variables</b>.
</li>
</ul>
After converting $B$ back into a linear system, solve for the 
dependent variables in terms of the independent variables. Then 
express the general vector solution as a linear combination of 
constant vectors parameterized by the free variables. This
is called <b>Parametric Form</b>.
</div>

<p>Let's see some examples.</p>

<table class="twocol">
<tbody><tr>
<td>
<b>Problem:</b> Solve 
$$\begin{array}{rcc}
y +z & = & 4 \, , \\ 3x + 6y -3z & = & 3 \, , \\
-2x -3y + 3z & = & 2 \, . \\ \end{array}$$
<br>
<b>Solution:</b> The associated augmented matrix is
$$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right] \ = \ \left[\begin{array}{ccc|c} 0 & 1 & 1 & 4 \\
3 & 6 & -3 & 3 \\ -2 & -3 & 3 & 2 \\ \end{array} \right],$$
which row reduces to
$$\left[\begin{array}{ccc|c} 1 & 0 & -3 & -7 \\
0 & 1 & 1 & 4 \\ 0 & 0 & 0 & 0 \\ \end{array} \right].$$
</td>
<td>
Thus $x$ and $y$ are dependent variables, and $z$ is free. This
gives the linear system
$$\begin{array}{rcc}
x - 3z & = & -7 \, , \\ y + z & = & 4 \, , \\
z & = & z \, . \\ \end{array}$$
Solve in terms of the free variable:
$$\begin{array}{rcc}
x & = & -7 + 3z \, , \\ y & = & 4 - z \, , \\
z & = & z \, . \\ \end{array}$$
Then the parametric form of the solution is
$${\bf x} = \left[ \begin{array}{c} -7+3z \\ 4-z \\ z \\ \end{array}
\right] = \left[ \begin{array}{c} -7 \\ 4 \\ 0 \\ \end{array}
\right] + z \left[ \begin{array}{c} 3 \\ -1 \\ 1 \\ \end{array}
\right]$$
</td>
</tr></tbody>
</table>

<br>

<table class="twocol">
<tbody><tr>
<td>
<b>Problem:</b> Solve 
$$\begin{array}{rcc}
x+3y-2z & = & 1 \, , \\ 2x+6y-4z & = & 2 \, , \\
3x+9y-6z & = & 3 \, . \\ \end{array}$$
<br>
<b>Solution:</b> The associated augmented matrix is
$$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right] \ = \ \left[\begin{array}{ccc|c} 1 & 3 & -2 & 1 \\
2 & 6 & -4 & 2 \\ 3 & 9 & -6 & 3 \\ \end{array} \right],$$
which row reduces to
$$\left[\begin{array}{ccc|c} 1 & 3 & -2 & 1 \\
0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ \end{array} \right].$$
</td>
<td>
Thus $x$ is the dependent variable, and $y$ and $z$ are free. This
gives the linear system
$$\begin{array}{rcc}
x+3y-2z & = & 1 \, , \\ y & = & y \, , \\
z & = & z \, . \\ \end{array}$$
Solve in terms of the free variables:
$$\begin{array}{rcc}
x & = & 1-3y+2z \, , \\ y & = & y \, , \\
z & = & z \, . \\ \end{array}$$
Then the parametric form of the solution is
$${\bf x} = \left[ \begin{array}{c} 1-3y+2z \\ y \\ z \\ \end{array}
\right] = \left[ \begin{array}{c} 1 \\ 0 \\ 0 \\ \end{array}
\right] + y \left[ \begin{array}{c} -3 \\ 1 \\ 0 \\ \end{array}
\right] + z \left[ \begin{array}{c} 2 \\ 0 \\ 1 \\ \end{array}
\right]
$$
</td>
</tr></tbody>
</table>

<br>

<div class="sectionhead" style="top: 0px;">5. Homogeneous and
Nonhomogeneous Systems</div>

<br>

<div class="bluebox">A linear system is <b>Homogeneous</b>
if all the constant terms are $0,$ i.e. if the vector of 
constants
$${\bf b} = \left[ \begin{array}{c} 0 \\ \vdots \\ 0 \\
\end{array} \right]$$
Otherwise, the system is <b>Nonhomogeneous</b>.
<br>
<p class="tabbed">A homogeneous system is always consistent. In 
particular, if $A$ is
the coefficient matrix for the system, then $A {\bf x} = {\bf 0}$ 
always has the <b>Trivial Solution</b>
$${\bf x} = \left[ \begin{array}{c} 0 \\ \vdots \\ 0 \\
\end{array} \right].$$
</p>
</div>

<p class="tabbed">All the examples we've seen so far have been 
nonhomogeneous. Let's see some examples of homogeneous systems.</p>

<table class="twocol">
<tbody><tr>
<td>
<b>Problem:</b> Solve 
$$\begin{array}{rcc}
x+y & = & 0 \, , \\ x-y & = & 0 \, . \\ \end{array}$$
<br>
<b>Solution:</b> The associated augmented matrix is
$$\left[ \begin{array}{c|c} A & {\bf b} \\ 
\end{array} \right] \ = \ \left[\begin{array}{cc|c} 1 & 1 & 0 \\
1 & -1 & 0 \\ \end{array} \right],$$
which row reduces to
</td>
<td>
$$\left[\begin{array}{cc|c} 1 & 0 & 0 \\
0 & 1 & 0 \\ \end{array} \right].$$
This gives the linear system
$$\begin{array}{rcc}
x & = & 0 \, , \\ y & = & 0 \, . \\ \end{array}$$
Thus the only solution is the trivial solution
$${\bf x} = \left[ \begin{array}{c} 0 \\ 0 \\ \end{array} \right].$$
</td>
</tr></tbody>
</table>

<p>Since the augmented column of a matrix associated with a 
homogeneous system is always zero, those entries never change under
elementary row operations. Thus it is customary to leave off the 
augmented column of zeroes during Gaussian elimination, and
simply row reduce the coefficient matrix.</p>

<table class="twocol">
<tbody><tr>
<td>
<b>Problem:</b> Solve 
$$\begin{array}{lcc}
x_1+3x_2-x_4 & = & 0 \, , \\ -3x_1-9x_2+x_3+x_4 & = & 0 \, , \\
2x_1+6x_2+x_3-4x_4 & = & 0 \, . \\ \end{array}$$
<br>
<b>Solution:</b> The associated coefficient matrix is
$$A \ = \ \left[\begin{array}{cccc} 1 & 3 & 0 & -1 \\
-3 & -9 & 1 & 1 \\ 2 & 6 & 1 & -4 \\ \end{array} \right],$$
which row reduces to
$$\left[\begin{array}{cccc} 1 & 3 & 0 & -1 \\
0 & 0 & 1 & -2 \\ 0 & 0 & 0 & 0 \\ \end{array} \right].$$
Thus $x_1$ and $x_3$ are dependent variables, and $x_2$ and $x_4$ 
are free.
</td>
<td>
This gives the linear system
$$\begin{array}{rcc}
x_1+3x_2-x_4 & = & 0 \, , \\ x_2 & = & x_2 \, , \\
x_3-2x_4 & = & 0 \, , \\
x_4 & = & x_4 \, . \\ \end{array}$$
Solve in terms of the free variables:
$$\begin{array}{rcc}
x_1 & = & -3x_2+x_4 \, , \\ x_2 & = & x_2 \, , \\
x_3 & = & 2x_4 \, , \\
x_4 & = & x_4 \, . \\ \end{array}$$
Then the parametric form of the solution is
$${\bf x} = \left[ \begin{array}{c} -3x_2+x_4 \\ x_2 \\ 2x_4 \\ x_4 \\ 
\end{array}
\right] = x_2 \left[ \begin{array}{c} -3 \\ 1 \\ 0 \\ 0 \\
\end{array} \right] + x_4 
\left[ \begin{array}{c} 1 \\ 0 \\ 2 \\ 1 \\ \end{array}
\right]
$$
</td>
</tr></tbody>
</table>


<br>

<br>

<br>


</body>
</html>